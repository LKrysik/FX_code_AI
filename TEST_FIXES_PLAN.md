# Plan Naprawy TestÃ³w - Wieloagentowy Proces

**Data utworzenia**: 2025-11-12
**Status**: PRZYGOTOWANIE
**Cel**: NaprawiÄ‡ 346 niepowodzÄ…cych siÄ™ testÃ³w (275 errors + 71 failures)

---

## EXECUTIVE SUMMARY - ROOT CAUSES

### Analiza WynikÃ³w TestÃ³w
- **Total tests**: 493
- **Errors**: 275 (55.8%) - gÅ‚Ã³wnie QuestDB connection timeouts
- **Failures**: 71 (14.4%) - bÅ‚Ä™dy logiczne
- **Success rate**: 29.8% (powinno byÄ‡ >95%)
- **Czas wykonania**: ~39 minut (powinno byÄ‡ <2 minuty)

### GÅ‚Ã³wne Przyczyny (Root Causes)

| RC# | Priorytet | Problem | Impact | Tests Affected |
|-----|-----------|---------|--------|----------------|
| RC#1 | CRITICAL | Heavy Fixture Initialization | KaÅ¼dy test tworzy caÅ‚y production app | 225 (81.5%) |
| RC#2 | CRITICAL | QuestDB Connection Timeout | 10s timeout Ã— 225 tests = 37.5 min | 225 (81.5%) |
| RC#3 | HIGH | Async/Await Complexity | Race conditions, deadlocks | 10 (3.6%) |
| RC#4 | HIGH | No Mocking/Test Doubles | Tests wymagajÄ… dziaÅ‚ajÄ…cego QuestDB | 225 (81.5%) |
| RC#5 | MEDIUM | Lock Contention | Nested locks w Container i QuestDB | 6 (2.2%) |
| RC#6 | MEDIUM | Cleanup Fixtures | autouse=True na wszystkich testach | 493 (100%) |

---

## ARCHITECTURE ANALIZY

### Problem: KaÅ¼dy Test Tworzy Full Production App

```python
# tests_e2e/conftest.py (CURRENT - PROBLEMATIC)
@pytest.fixture(scope="function")
def app():
    return create_unified_app()  # â† FULL PRODUCTION INITIALIZATION!
```

### Co siÄ™ dzieje podczas kaÅ¼dego testu:

```
Test starts
  â†’ conftest.py app() fixture
    â†’ create_unified_app()
      â†’ lifespan startup (async)
        â†’ Container initialization
          â”œâ”€â”€ EventBus
          â”œâ”€â”€ Logger
          â”œâ”€â”€ Settings
          â”œâ”€â”€ WebSocketServer â†’ QuestDB connection #1
          â”œâ”€â”€ UnifiedTradingController
          â”‚   â””â”€â”€ StreamingIndicatorEngine
          â”‚       â””â”€â”€ IndicatorVariantRepository
          â”‚           â””â”€â”€ QuestDBProvider â†’ CONNECTION TIMEOUT âŒ (10s)
          â”œâ”€â”€ StrategyManager â†’ QuestDB connection #2
          â”œâ”€â”€ LiveMarketAdapter â†’ QuestDB connection #3
          â”œâ”€â”€ SessionManager â†’ QuestDB connection #4
          â”œâ”€â”€ StrategyStorage â†’ QuestDB connection #5
          â””â”€â”€ PaperTradingPersistence â†’ QuestDB connection #6
```

**Rezultat**: 225 tests Ã— 10s timeout = **37.5 minutes wasted**

---

## PLAN NAPRAWY - 6 AGENTÃ“W + KOORDYNATOR

### Organizacja ZespoÅ‚u

```
KOORDYNATOR (Agent 1)
     â”‚
     â”œâ”€â”€â†’ Agent 2: Fixture Refactoring
     â”œâ”€â”€â†’ Agent 3: Container Mocking
     â”œâ”€â”€â†’ Agent 4: Cleanup Optimization
     â”œâ”€â”€â†’ Agent 5: Test Categorization
     â””â”€â”€â†’ Agent 6: Code Review & Verification
```

### Workflow

1. **Koordynator** przydziela zadania agentom
2. Agenci pracujÄ… **rÃ³wnolegle** (gdzie moÅ¼liwe)
3. **Koordynator** monitoruje postÄ™py
4. **Agent 6** weryfikuje zmiany przed merge
5. **Koordynator** scala zmiany i uruchamia testy

---

## AGENT 1: KOORDYNATOR

### Rola
- Nadzoruje caÅ‚y proces naprawy
- Przydziela zadania agentom
- Monitoruje postÄ™py i wykrywa blokery
- Sprawdza spÃ³jnoÅ›Ä‡ zmian miÄ™dzy agentami
- Wykrywa problemy architektoniczne
- Scala zmiany i uruchamia testy walidacyjne

### OdpowiedzialnoÅ›ci

1. **Pre-Flight Check**
   - SprawdÅº czy QuestDB jest uruchomiony
   - SprawdÅº historiÄ™ git dla kluczowych plikÃ³w
   - Zidentyfikuj potencjalne konflikty miÄ™dzy zadaniami agentÃ³w

2. **Task Assignment**
   - Priorytetyzuj zadania (CRITICAL â†’ HIGH â†’ MEDIUM)
   - Zidentyfikuj zaleÅ¼noÅ›ci miÄ™dzy zadaniami
   - Przydziel zadania agentom z jasnym scope

3. **Progress Monitoring**
   - Sprawdzaj co 5 minut status kaÅ¼dego agenta
   - Wykryj blokery i realokuj zasoby
   - Eskaluj problemy wymagajÄ…ce decyzji uÅ¼ytkownika

4. **Quality Assurance**
   - Weryfikuj czy zmiany sÄ… zgodne z architekturÄ…
   - SprawdÅº czy nie powstaÅ‚ dead code
   - SprawdÅº czy nie powstaÅ‚y backward compatibility hacks
   - Zweryfikuj spÃ³jnoÅ›Ä‡ zmian

5. **Integration & Testing**
   - Scala zmiany od agentÃ³w
   - RozwiÄ…Å¼ konflikty merge
   - Uruchom testy: `python run_tests.py --api --fast`
   - Raportuj wyniki

### Metryki Sukcesu
- Wszyscy agenci zakoÅ„czyli pracÄ™ bez blockerÃ³w
- Zmiany sÄ… spÃ³jne i zgodne z architekturÄ…
- Test success rate: >95%
- Test execution time: <2 minuty

---

## AGENT 2: FIXTURE REFACTORING (RC#1, RC#4)

### Zadania

#### 1. Create Lightweight App Fixture
**Cel**: FastAPI app bez heavy initialization

**Pliki do modyfikacji**:
- `tests_e2e/conftest.py`

**Zmiany**:

```python
# tests_e2e/conftest.py

@pytest.fixture(scope="session")
def mock_questdb_provider():
    """Lightweight QuestDB mock - no real database"""
    from unittest.mock import AsyncMock, MagicMock
    from src.data_feed.questdb_provider import QuestDBProvider

    mock = MagicMock(spec=QuestDBProvider)
    mock.initialize = AsyncMock()
    mock.is_healthy = AsyncMock(return_value=True)
    mock.execute_query = AsyncMock(return_value=[])
    mock.fetch_tick_prices = AsyncMock(return_value=[])
    mock.pg_pool = MagicMock()

    return mock


@pytest.fixture(scope="session")
def test_settings():
    """Minimal settings for testing"""
    from src.infrastructure.config.settings import AppSettings

    settings = AppSettings()
    settings.trading.mode = "mock"  # Don't connect to real exchange
    settings.questdb.pg_host = "127.0.0.1"  # Localhost for CI
    settings.questdb.pg_port = 8812

    return settings


@pytest.fixture(scope="function")
def lightweight_container(mock_questdb_provider, test_settings):
    """Container with mocked QuestDB - no database required"""
    from src.infrastructure.container import Container
    from src.core.event_bus import EventBus
    from src.infrastructure.logger import StructuredLogger

    event_bus = EventBus()
    logger = StructuredLogger("Test", test_settings.logging)
    container = Container(test_settings, event_bus, logger)

    # Replace QuestDB provider with mock
    container._singleton_services["questdb_provider"] = mock_questdb_provider

    return container


@pytest.fixture(scope="function")
def lightweight_app(lightweight_container):
    """FastAPI app with mocked dependencies - FAST"""
    from fastapi import FastAPI
    from contextlib import asynccontextmanager

    # Create app WITHOUT lifespan (skip heavy initialization)
    app = FastAPI()
    app.state.container = lightweight_container

    # Register routes (but skip lifespan startup)
    # ... TODO: import and register route handlers ...

    return app


# DEPRECATED: Old heavy fixture
@pytest.fixture(scope="function")
def app():
    """
    DEPRECATED: Use lightweight_app instead.

    This fixture creates a FULL production app with QuestDB connections.
    Only use for integration tests that REQUIRE real database.
    """
    from src.api.unified_server import create_unified_app
    return create_unified_app()
```

**Walidacja**:
- [ ] `lightweight_app` nie wymaga QuestDB
- [ ] Test z `lightweight_app` wykonuje siÄ™ <100ms
- [ ] SprawdÅº git history `conftest.py` - czy byÅ‚y niedawne zmiany?
- [ ] Uzasadnij czemu ta zmiana nie cofnie poprzednich fix'Ã³w

#### 2. Create Test-Specific Mocks

**Pliki do modyfikacji**:
- `tests_e2e/mocks/__init__.py` (nowy plik)
- `tests_e2e/mocks/indicator_engine.py` (nowy plik)
- `tests_e2e/mocks/strategy_manager.py` (nowy plik)

**Zmiany**:

```python
# tests_e2e/mocks/indicator_engine.py

from unittest.mock import AsyncMock, MagicMock
from src.domain.services.streaming_indicator_engine import StreamingIndicatorEngine


def create_mock_indicator_engine():
    """Mock StreamingIndicatorEngine - no database"""
    mock = MagicMock(spec=StreamingIndicatorEngine)

    # Mock async methods
    mock.start = AsyncMock()
    mock.stop = AsyncMock()
    mock.create_variant = AsyncMock(return_value="variant_id_123")
    mock.get_indicators = AsyncMock(return_value={
        "BTC_USDT": {
            "TWPA_5min": {"value": 50000.0, "timestamp": "2025-11-12T10:00:00Z"}
        }
    })

    return mock
```

**Walidacja**:
- [ ] Mocks majÄ… wszystkie metody uÅ¼ywane przez testy
- [ ] Mocks zwracajÄ… realistyczne dane
- [ ] SprawdÅº czy nie duplikujesz istniejÄ…cych mockÃ³w

#### 3. Update Test Files to Use Lightweight Fixtures

**Pliki do modyfikacji**:
- `tests_e2e/api/test_indicators.py`
- `tests_e2e/api/test_auth.py`
- `tests_e2e/api/test_misc.py`
- ... (wszystkie test_*.py files)

**PrzykÅ‚ad**:

```python
# tests_e2e/api/test_indicators.py (BEFORE)
def test_get_indicators_for_symbol(self, api_client):
    """Test GET /api/v1/indicators/{symbol}"""
    response = api_client.get("/api/v1/indicators/BTC_USDT")
    assert response.status_code == 200


# tests_e2e/api/test_indicators.py (AFTER)
@pytest.mark.fast  # New marker
def test_get_indicators_for_symbol(self, lightweight_api_client):
    """Test GET /api/v1/indicators/{symbol}"""
    response = lightweight_api_client.get("/api/v1/indicators/BTC_USDT")
    assert response.status_code == 200
```

**Walidacja**:
- [ ] Testy uÅ¼ywajÄ… `lightweight_api_client` zamiast `api_client`
- [ ] Testy z markerem `@pytest.mark.fast` wykonujÄ… siÄ™ <100ms
- [ ] SprawdÅº git log dla kaÅ¼dego modyfikowanego pliku
- [ ] Uzasadnij czemu zmiana nie zÅ‚amie innych testÃ³w

### Metryki Sukcesu
- [ ] 225 testÃ³w nie wymaga juÅ¼ QuestDB
- [ ] Test execution time: <100ms per test (fast tests)
- [ ] Wszystkie testy z `@pytest.mark.fast` przechodzÄ…

### Ryzyka i Mitigacje

| Ryzyko | PrawdopodobieÅ„stwo | Mitigacja |
|--------|-------------------|-----------|
| Mocks nie pokrywajÄ… wszystkich use cases | Medium | Code review by Agent 6 |
| Testy tracÄ… wartoÅ›Ä‡ (testujÄ… mocks, nie kod) | High | Agent 5 segreguje unit vs integration |
| Breaking changes w API | Low | Agent 1 sprawdza git history |

---

## AGENT 3: CONTAINER MOCKING (RC#2, RC#3)

### Zadania

#### 1. Create TestContainer Class

**Cel**: Container dla testÃ³w bez QuestDB connections

**Pliki do modyfikacji**:
- `tests_e2e/test_container.py` (nowy plik)

**Zmiany**:

```python
# tests_e2e/test_container.py

from src.infrastructure.container import Container
from unittest.mock import AsyncMock, MagicMock


class TestContainer(Container):
    """
    Lightweight Container for testing.

    Overrides expensive factories to return mocks.
    Use for unit tests that don't need real database.
    """

    async def create_questdb_provider(self):
        """Mock QuestDBProvider - no database"""
        from src.data_feed.questdb_provider import QuestDBProvider

        mock = MagicMock(spec=QuestDBProvider)
        mock.initialize = AsyncMock()
        mock.is_healthy = AsyncMock(return_value=True)
        mock.execute_query = AsyncMock(return_value=[])
        mock.fetch_tick_prices = AsyncMock(return_value=[])
        mock.pg_pool = MagicMock()

        return mock

    async def create_streaming_indicator_engine(self):
        """Mock StreamingIndicatorEngine - no database"""
        from src.domain.services.streaming_indicator_engine import StreamingIndicatorEngine

        mock = MagicMock(spec=StreamingIndicatorEngine)
        mock.start = AsyncMock()
        mock.stop = AsyncMock()
        mock.create_variant = AsyncMock(return_value="variant_123")
        mock.get_indicators = AsyncMock(return_value={})

        return mock

    async def create_strategy_manager(self):
        """Mock StrategyManager - no database"""
        from src.domain.services.strategy_manager import StrategyManager

        mock = MagicMock(spec=StrategyManager)
        mock.initialize_strategies = AsyncMock()
        mock.start = AsyncMock()
        mock.stop = AsyncMock()

        return mock

    # TODO: Override other expensive factories:
    # - create_live_market_adapter
    # - create_session_manager
    # - create_strategy_storage
    # - create_paper_trading_persistence
```

**Walidacja**:
- [ ] TestContainer nie Å‚Ä…czy siÄ™ z QuestDB
- [ ] Wszystkie mock'i majÄ… spec= (type checking)
- [ ] SprawdÅº git history `src/infrastructure/container.py`
- [ ] Uzasadnij czy ta zmiana nie koliduje z poprzednimi fix'ami

#### 2. Add QuestDB Health Check

**Cel**: Fail fast jeÅ›li QuestDB nie dziaÅ‚a

**Pliki do modyfikacji**:
- `tests_e2e/conftest.py`

**Zmiany**:

```python
# tests_e2e/conftest.py

import pytest
import asyncio


def pytest_configure(config):
    """
    Run BEFORE any tests - check if QuestDB is available.

    For integration tests that require database.
    """
    # Skip health check if only running unit tests
    markers = config.option.markexpr or ""
    if "integration" not in markers and "database" not in markers:
        return  # Unit tests don't need QuestDB

    print("\nðŸ” Checking QuestDB availability...")

    try:
        import asyncpg

        async def check_questdb():
            try:
                pool = await asyncpg.create_pool(
                    host='127.0.0.1',
                    port=8812,
                    user='admin',
                    password='quest',
                    database='qdb',
                    min_size=1,
                    max_size=2,
                    timeout=2.0  # Fast check
                )
                await pool.close()
                return True
            except Exception as e:
                return False, str(e)

        result = asyncio.run(check_questdb())

        if result is True:
            print("âœ… QuestDB is running on port 8812")
        else:
            error_msg = result[1] if isinstance(result, tuple) else "Unknown error"
            pytest.exit(
                f"\nâŒ QuestDB is NOT running on port 8812.\n"
                f"Error: {error_msg}\n\n"
                f"Integration tests require QuestDB.\n"
                f"Start QuestDB:\n"
                f"  1. python database/questdb/install_questdb.py\n"
                f"  2. .\\start_all.ps1\n\n"
                f"Or run only unit tests:\n"
                f"  pytest -m 'not database'\n",
                returncode=1
            )
    except Exception as e:
        pytest.exit(f"QuestDB health check failed: {e}", returncode=1)
```

**Walidacja**:
- [ ] Health check wykonuje siÄ™ <2s
- [ ] Health check wykrywa brak QuestDB
- [ ] Health check nie blokuje unit testÃ³w
- [ ] SprawdÅº git history - czy byÅ‚ podobny health check?

#### 3. Optimize Container Initialization Order

**Cel**: Zmniejsz liczbÄ™ QuestDB connections w production

**Pliki do modyfikacji**:
- `src/infrastructure/container.py`

**Analiza wymagana**:
1. SprawdÅº git log `src/infrastructure/container.py` - ostatnie 20 commitÃ³w
2. Zidentyfikuj ktÃ³re serwisy MUSZÄ„ mieÄ‡ QuestDB przy starcie
3. Zidentyfikuj ktÃ³re serwisy mogÄ… byÄ‡ lazy-loaded

**Zmiany**:

```python
# src/infrastructure/container.py

# BEFORE: Wszystkie serwisy tworzone przy starcie
async def create_streaming_indicator_engine(self):
    variant_repository = await self.create_indicator_variant_repository()  # â† QuestDB
    engine = StreamingIndicatorEngine(...)
    await engine.start()  # â† Loads from DB
    return engine


# AFTER: Lazy loading dla testÃ³w
async def create_streaming_indicator_engine(self, lazy_init: bool = False):
    """
    Create StreamingIndicatorEngine.

    Args:
        lazy_init: If True, skip database loading (for tests)
    """
    variant_repository = await self.create_indicator_variant_repository()
    engine = StreamingIndicatorEngine(...)

    if not lazy_init:
        await engine.start()  # Load variants from DB

    return engine
```

**Walidacja**:
- [ ] Production behavior nie zmienia siÄ™
- [ ] Tests mogÄ… uÅ¼ywaÄ‡ `lazy_init=True`
- [ ] SprawdÅº czy nie zÅ‚amiesz istniejÄ…cych callsites
- [ ] Uzasadnij czemu to nie jest backward compatibility hack

### Metryki Sukcesu
- [ ] TestContainer dostÄ™pny dla wszystkich testÃ³w
- [ ] Health check wykrywa brak QuestDB
- [ ] Container initialization time: <100ms (w testach)

### Ryzyka i Mitigacje

| Ryzyko | PrawdopodobieÅ„stwo | Mitigacja |
|--------|-------------------|-----------|
| Mocks nie pokrywajÄ… real Container behavior | High | Agent 5 segreguje unit vs integration |
| lazy_init flag proliferuje przez codebase | Medium | Code review by Agent 6 |
| Health check ma false positives | Low | Test on CI |

---

## AGENT 4: CLEANUP OPTIMIZATION (RC#6)

### Zadania

#### 1. Remove autouse from Cleanup Fixtures

**Cel**: Cleanup tylko dla testÃ³w ktÃ³re tego potrzebujÄ…

**Pliki do modyfikacji**:
- `tests_e2e/conftest.py`

**Zmiany**:

```python
# tests_e2e/conftest.py

# BEFORE
@pytest.fixture(autouse=True)  # â† Runs for EVERY test
def cleanup_strategies(api_client):
    yield
    # Cleanup logic...


# AFTER
@pytest.fixture  # â† Removed autouse=True
def cleanup_strategies(api_client):
    """
    Manual cleanup for strategy tests.

    Usage:
        def test_create_strategy(api_client, cleanup_strategies):
            # Test creates strategies
            # cleanup_strategies will delete them after test
    """
    yield
    # Cleanup logic...


# Add explicit fixture for tests that need it
@pytest.fixture
def strategy_test(api_client, cleanup_strategies):
    """
    Convenience fixture for strategy tests.

    Automatically includes cleanup_strategies.
    """
    return api_client
```

**Walidacja**:
- [ ] Cleanup nie uruchamia siÄ™ dla testÃ³w ktÃ³re nie tworzÄ… strategies
- [ ] Tests ktÃ³re POTRZEBUJÄ„ cleanup nadal dziaÅ‚ajÄ…
- [ ] SprawdÅº git log - czy cleanup byÅ‚ dodany z powodu?

#### 2. Improve Cleanup Error Handling

**Cel**: Zrozum dlaczego cleanup fail'uje

**Pliki do modyfikacji**:
- `tests_e2e/conftest.py`

**Zmiany**:

```python
# tests_e2e/conftest.py

# BEFORE
except Exception:
    pass  # â† Silent failures hide real problems


# AFTER
except Exception as e:
    # Log cleanup failures for debugging
    import logging
    logging.warning(f"Test cleanup failed: {type(e).__name__}: {e}")
    # Don't fail test due to cleanup failure, but report it
```

**Walidacja**:
- [ ] Cleanup failures sÄ… logowane
- [ ] Cleanup failures nie psujÄ… testÃ³w
- [ ] SprawdÅº czy cleanup failures wskazujÄ… na real bugs

#### 3. Add Cleanup Performance Metrics

**Cel**: Zmierz czas cleanup

**Pliki do modyfikacji**:
- `tests_e2e/conftest.py`

**Zmiany**:

```python
# tests_e2e/conftest.py

import time

@pytest.fixture
def cleanup_strategies(api_client):
    yield

    # Measure cleanup time
    start = time.time()
    try:
        # Cleanup logic...
        pass
    finally:
        duration = time.time() - start
        if duration > 1.0:  # Slow cleanup
            import logging
            logging.warning(f"Slow cleanup: {duration:.2f}s")
```

**Walidacja**:
- [ ] Cleanup time < 100ms per fixture
- [ ] Slow cleanups sÄ… identyfikowane

### Metryki Sukcesu
- [ ] Cleanup fixtures: autouse=False
- [ ] Cleanup time per test: <100ms
- [ ] Cleanup failures sÄ… logowane (nie silent)

---

## AGENT 5: TEST CATEGORIZATION (RC#4)

### Zadania

#### 1. Add Test Markers

**Cel**: Segreguj unit vs integration tests

**Pliki do modyfikacji**:
- `pytest.ini`
- Wszystkie test files

**Zmiany**:

```ini
# pytest.ini

[pytest]
markers =
    fast: Fast unit tests (<100ms, no database)
    slow: Slow tests (>1s)
    database: Tests that require QuestDB
    integration: Integration tests (multiple components)
    e2e: End-to-end tests (full system)
    frontend: Frontend tests (Playwright)
    api: API endpoint tests
    unit: Unit tests (single component, mocked dependencies)
```

```python
# Example: tests_e2e/api/test_indicators.py

@pytest.mark.fast
@pytest.mark.unit
def test_get_indicators_for_symbol(lightweight_api_client):
    """Unit test - mocked dependencies"""
    ...


@pytest.mark.slow
@pytest.mark.database
@pytest.mark.integration
def test_indicators_with_real_database(api_client):
    """Integration test - requires QuestDB"""
    ...
```

**Walidacja**:
- [ ] Wszystkie testy majÄ… marker (fast/slow)
- [ ] Wszystkie testy majÄ… marker (unit/integration/e2e)
- [ ] Testy z `@pytest.mark.fast` nie uÅ¼ywajÄ… QuestDB

#### 2. Split Test Files

**Cel**: Oddziel unit tests od integration tests

**Struktura**:

```
tests_e2e/
  unit/           # Fast tests, mocked dependencies
    test_indicators_unit.py
    test_auth_unit.py
  integration/    # Require QuestDB
    test_indicators_integration.py
    test_auth_integration.py
  e2e/            # Full system tests
    test_trading_flow.py
```

**Walidacja**:
- [ ] Unit tests nie wymagajÄ… QuestDB
- [ ] Integration tests sprawdzajÄ… real DB interactions
- [ ] Nie ma duplikacji testÃ³w

#### 3. Update run_tests.py

**Cel**: Support dla nowych markerÃ³w

**Pliki do modyfikacji**:
- `run_tests.py`

**Zmiany**:

```python
# run_tests.py

parser.add_argument('--unit', action='store_true',
                    help='Run only unit tests (fast, no database)')
parser.add_argument('--database', action='store_true',
                    help='Run tests that require database')

# Build pytest command
if args.unit:
    pytest_args.extend(['-m', 'unit'])
elif args.database:
    pytest_args.extend(['-m', 'database'])
```

**Walidacja**:
- [ ] `python run_tests.py --unit` dziaÅ‚a
- [ ] `python run_tests.py --database` wymaga QuestDB

### Metryki Sukcesu
- [ ] 100% testÃ³w ma marker fast/slow
- [ ] 100% testÃ³w ma marker unit/integration/e2e
- [ ] `pytest -m unit` wykonuje siÄ™ <10s

---

## AGENT 6: CODE REVIEW & VERIFICATION

### Zadania

#### 1. Review Changes from Other Agents

**Cel**: SprawdÅº spÃ³jnoÅ›Ä‡ i jakoÅ›Ä‡ zmian

**Checklist**:
- [ ] Zmiany Agent 2: Fixtures sÄ… lightweight, nie Å‚amiÄ… istniejÄ…cych testÃ³w
- [ ] Zmiany Agent 3: TestContainer pokrywa wszystkie use cases
- [ ] Zmiany Agent 4: Cleanup fixtures sÄ… optymalne
- [ ] Zmiany Agent 5: Markers sÄ… poprawnie zastosowane

**Pliki do sprawdzenia**:
- Wszystkie pliki zmodyfikowane przez AgentÃ³w 2-5

**Metoda**:
1. Przeczytaj kaÅ¼dÄ… zmianÄ™
2. SprawdÅº git history dla kontekstu
3. Zidentyfikuj potencjalne problemy:
   - Dead code
   - Backward compatibility hacks
   - Race conditions
   - Memory leaks
   - Inconsistent naming

#### 2. Run Static Analysis

**Cel**: Wykryj problemy przed uruchomieniem testÃ³w

**Komendy**:
```bash
# Type checking
mypy src/ tests_e2e/

# Code quality
pylint src/infrastructure/container.py
pylint tests_e2e/conftest.py

# Security
bandit -r src/
```

**Walidacja**:
- [ ] Brak nowych type errors
- [ ] Brak nowych pylint errors
- [ ] Brak nowych security issues

#### 3. Verify Git History Compatibility

**Cel**: Upewnij siÄ™ Å¼e zmiany nie cofajÄ… poprzednich fix'Ã³w

**Dla kaÅ¼dego zmodyfikowanego pliku**:
```bash
git log --oneline -20 -- <filepath>
git diff <last_commit> -- <filepath>
```

**Analiza**:
- [ ] Czy byÅ‚y niedawne fix'y w tym obszarze?
- [ ] Czy nasze zmiany nie cofajÄ… tych fix'Ã³w?
- [ ] Czy commit messages wskazujÄ… na problemy?

**PrzykÅ‚ad**:
```bash
# tests_e2e/conftest.py history
git log --oneline -10 -- tests_e2e/conftest.py

# Output:
# e2a3f5d Fix CRITICAL: UnboundLocalError in QuestDB error handling
# 16c229f Fix CRITICAL: Add comprehensive error handling for QuestDB
# ...

# QUESTION: Czy nasze zmiany w conftest.py kolidujÄ… z tymi fix'ami?
# ANSWER: Nie, fix'y byÅ‚y w src/data_feed/questdb_provider.py, nie conftest.py
```

#### 4. Architecture Compliance Check

**Cel**: SprawdÅº zgodnoÅ›Ä‡ z architekturÄ…

**Checklist**:
- [ ] Dependency Injection: Czy konstruktory uÅ¼ywajÄ… DI?
- [ ] EventBus: Czy wszystkie handlery sÄ… async?
- [ ] Logging: Czy uÅ¼ywamy StructuredLogger (nie print)?
- [ ] Error Handling: Czy RuntimeError ma sensowny message?
- [ ] Single Source of Truth: Czy nie ma duplikacji?

**Pliki do sprawdzenia**:
- `src/infrastructure/container.py`
- `tests_e2e/conftest.py`
- `tests_e2e/test_container.py`

### Metryki Sukcesu
- [ ] Brak architecture violations
- [ ] Brak regressions (cofniÄ™Ä‡ poprzednich fix'Ã³w)
- [ ] Brak dead code
- [ ] Consistent naming i style

---

## DEPENDENCIES & EXECUTION ORDER

### Phase 1: Preparation (Parallel)
```
Agent 1 (Koordynator) â†’ Pre-Flight Check
  â”œâ†’ Agent 6 â†’ Git History Analysis (parallel)
  â””â†’ Agent 6 â†’ Architecture Review (parallel)
```

### Phase 2: Core Changes (Parallel where possible)
```
Agent 2 â†’ Fixture Refactoring
  â”œâ†’ Create lightweight_app fixture
  â”œâ†’ Create mocks
  â””â†’ [BLOCKER for Agent 5]

Agent 3 â†’ Container Mocking
  â”œâ†’ Create TestContainer
  â”œâ†’ Add health check
  â””â†’ [PARALLEL with Agent 2]

Agent 4 â†’ Cleanup Optimization
  â”œâ†’ Remove autouse
  â””â†’ [PARALLEL with Agents 2, 3]
```

### Phase 3: Integration (Sequential)
```
Agent 5 â†’ Test Categorization
  â”œâ†’ [REQUIRES Agent 2 completion]
  â”œâ†’ Add markers
  â””â†’ Split test files

Agent 6 â†’ Code Review
  â”œâ†’ [REQUIRES Agents 2-5 completion]
  â”œâ†’ Review all changes
  â””â†’ Run static analysis
```

### Phase 4: Validation (Sequential)
```
Agent 1 (Koordynator) â†’ Integration & Testing
  â”œâ†’ Merge all changes
  â”œâ†’ Run: pytest -m unit
  â”œâ†’ Run: pytest -m fast
  â”œâ†’ Run: python run_tests.py --api --fast
  â””â†’ Report results
```

---

## SUCCESS CRITERIA

### Performance Metrics
- [ ] Test execution time: <2 minutes (was: 39 minutes)
- [ ] Test success rate: >95% (was: 29.8%)
- [ ] Unit test speed: <100ms per test
- [ ] Integration test speed: <5s per test

### Quality Metrics
- [ ] Test coverage: >80% (unchanged)
- [ ] No new type errors
- [ ] No new security issues
- [ ] No dead code introduced

### Architecture Metrics
- [ ] No backward compatibility hacks
- [ ] No code duplication
- [ ] Consistent naming and style
- [ ] All fixtures documented

---

## ROLLBACK PLAN

JeÅ›li naprawy fail'ujÄ…:

1. **Identify failure point**
   ```bash
   git log --oneline -10
   git diff HEAD~5..HEAD
   ```

2. **Rollback changes**
   ```bash
   git reset --hard <commit_before_changes>
   ```

3. **Analyze failure**
   - SprawdÅº logi testÃ³w
   - Zidentyfikuj root cause
   - Update plan naprawy

4. **Retry with updated plan**

---

## COMMUNICATION PROTOCOL

### Agent â†’ Koordynator
- Raportuj co 5 minut status
- Eskaluj blokery natychmiast
- Raportuj completion z evidence

### Koordynator â†’ Agent
- Przydziel task z jasnym scope
- Podaj expected deliverables
- WskaÅ¼ dependencies

### Koordynator â†’ User
- Raportuj progress co 10 minut
- Eskaluj decyzje wymagajÄ…ce input
- Raportuj completion z metrics

---

## APPENDIX: ERROR CATEGORIES

### Full Error Breakdown
```
QuestDB Connection (StreamingIndicatorEngine): 225 (81.5%)
  â†³ Root Cause: RC#1, RC#2, RC#4
  â†³ Fix: Agent 2, Agent 3

Status Code Mismatch: 10 (3.6%)
  â†³ Root Cause: RC#4 (tests expect 404, get 500)
  â†³ Fix: Agent 2 (proper mocking)

QuestDB Timeout: 6 (2.2%)
  â†³ Root Cause: RC#2
  â†³ Fix: Agent 3 (health check)

KeyError: 3 (1.1%)
  â†³ Root Cause: RC#3 (async init order)
  â†³ Fix: Code fixes (not in this plan)

Playwright Timeout: 3 (1.1%)
  â†³ Root Cause: RC#1 (frontend waits for backend)
  â†³ Fix: Agent 2 (lightweight backend)

Strategy Storage Init: 2 (0.7%)
  â†³ Root Cause: RC#2
  â†³ Fix: Agent 3

TypeError: 2 (0.7%)
  â†³ Root Cause: Code bugs (not test infrastructure)
  â†³ Fix: Separate fix (not in this plan)

AttributeError: 1 (0.4%)
  â†³ Root Cause: Code bug (RiskManager API change)
  â†³ Fix: Separate fix (not in this plan)
```

---

## NEXT STEPS

1. **Koordynator (Agent 1)**: Review plan, assign tasks
2. **All Agents**: Acknowledge task assignment
3. **Execute**: Phase 1 â†’ Phase 2 â†’ Phase 3 â†’ Phase 4
4. **Validate**: Run full test suite
5. **Report**: Deliver results to user

**Estimated Time**: 2-3 hours (with 6 parallel agents)
